-- POSTGRES IMPORT SCRIPT: run with psql to load CSVs exported from H2
-- Requires CSV files under data/migration/h2_to_postgres/exports generated by h2-export.sql
-- Usage (Windows cmd):
--   psql "host=<HOST> port=<PORT> dbname=<DB> user=<USER> password=<PASSWORD>" -f scripts/migration/h2_to_postgres/postgres-import.sql
-- Or using env PGPASSWORD:
--   set PGPASSWORD=<PASSWORD>
--   psql -h <HOST> -p <PORT> -U <USER> -d <DB> -f scripts/migration/h2_to_postgres/postgres-import.sql

\set ON_ERROR_STOP on

BEGIN;

-- Optional: ensure schema exists; your application already creates schema via schema.sql
-- You can uncomment the next line if needed:
-- \i ../../src/main/resources/schema.sql

-- If this is a fresh migration, it's safer to truncate in FK order
TRUNCATE TABLE user_roles RESTART IDENTITY CASCADE;
TRUNCATE TABLE roles RESTART IDENTITY CASCADE;
TRUNCATE TABLE users RESTART IDENTITY CASCADE;
TRUNCATE TABLE article_tags RESTART IDENTITY CASCADE;
TRUNCATE TABLE articles RESTART IDENTITY CASCADE;
TRUNCATE TABLE blogs RESTART IDENTITY CASCADE;
TRUNCATE TABLE ebooks_content RESTART IDENTITY CASCADE;
TRUNCATE TABLE newsletter_subscribers RESTART IDENTITY CASCADE;

-- Load reference tables first
\copy roles(id, name) FROM 'data/migration/h2_to_postgres/exports/roles.csv' WITH (FORMAT csv, HEADER true)
\copy users(id, username, password) FROM 'data/migration/h2_to_postgres/exports/users.csv' WITH (FORMAT csv, HEADER true)

-- Load main content tables
\copy blogs(id, title, content, author, publish_date, created_at, updated_at) FROM 'data/migration/h2_to_postgres/exports/blogs.csv' WITH (FORMAT csv, HEADER true)
\copy articles(id, title, description, content, read_time, category, created_at, updated_at) FROM 'data/migration/h2_to_postgres/exports/articles.csv' WITH (FORMAT csv, HEADER true)
\copy article_tags(article_id, tag) FROM 'data/migration/h2_to_postgres/exports/article_tags.csv' WITH (FORMAT csv, HEADER true)
\copy ebooks_content(id, content_json, updated_at) FROM 'data/migration/h2_to_postgres/exports/ebooks_content.csv' WITH (FORMAT csv, HEADER true)
\copy newsletter_subscribers(id, email, created_at, active, unsubscribed_at) FROM 'data/migration/h2_to_postgres/exports/newsletter_subscribers.csv' WITH (FORMAT csv, HEADER true)

-- Load join table last (depends on users/roles)
\copy user_roles(user_id, role_id) FROM 'data/migration/h2_to_postgres/exports/user_roles.csv' WITH (FORMAT csv, HEADER true)

-- Align identity sequences with max(id) so future inserts don't collide
-- Note: pg_get_serial_sequence works for identity/serial columns in modern Postgres
SELECT setval(pg_get_serial_sequence('roles','id'), COALESCE((SELECT MAX(id) FROM roles), 0) + 1, false);
SELECT setval(pg_get_serial_sequence('users','id'), COALESCE((SELECT MAX(id) FROM users), 0) + 1, false);
SELECT setval(pg_get_serial_sequence('blogs','id'), COALESCE((SELECT MAX(id) FROM blogs), 0) + 1, false);
SELECT setval(pg_get_serial_sequence('articles','id'), COALESCE((SELECT MAX(id) FROM articles), 0) + 1, false);
SELECT setval(pg_get_serial_sequence('ebooks_content','id'), COALESCE((SELECT MAX(id) FROM ebooks_content), 0) + 1, false);
SELECT setval(pg_get_serial_sequence('newsletter_subscribers','id'), COALESCE((SELECT MAX(id) FROM newsletter_subscribers), 0) + 1, false);

COMMIT;

-- Verification (optional): counts
-- SELECT 'roles' AS table, COUNT(*) FROM roles
-- UNION ALL SELECT 'users', COUNT(*) FROM users
-- UNION ALL SELECT 'user_roles', COUNT(*) FROM user_roles
-- UNION ALL SELECT 'blogs', COUNT(*) FROM blogs
-- UNION ALL SELECT 'articles', COUNT(*) FROM articles
-- UNION ALL SELECT 'article_tags', COUNT(*) FROM article_tags
-- UNION ALL SELECT 'ebooks_content', COUNT(*) FROM ebooks_content
-- UNION ALL SELECT 'newsletter_subscribers', COUNT(*) FROM newsletter_subscribers;
